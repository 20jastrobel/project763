{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bf35cbd",
   "metadata": {},
   "source": [
    "# Deep Learning Exploration Notebook\n",
    "\n",
    "This notebook is for exploring database files and training neural networks to assign weights.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Imports\n",
    "2. Data Loading and Exploration\n",
    "3. Data Preprocessing\n",
    "4. Model Definition and Training\n",
    "5. Evaluation and Feature Weight Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797f098",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6dba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Custom modules\n",
    "from data_loader import DataProcessor, get_data_loaders\n",
    "from model import WeightAssignmentNetwork, create_model\n",
    "from utils import set_seed, get_device\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Get device\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c6174e",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration\n",
    "\n",
    "Upload your database files to the `data/` directory and update the path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data file - update the path to your file\n",
    "data_path = '../data/your_data_file.csv'  # Change this to your file\n",
    "\n",
    "# Initialize data processor\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Uncomment when you have data:\n",
    "# df = processor.load_data(data_path)\n",
    "# print(f\"Data shape: {df.shape}\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736be11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration - uncomment when data is loaded\n",
    "# print(\"Data Info:\")\n",
    "# df.info()\n",
    "# print(\"\\nStatistics:\")\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e96db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data distribution - uncomment when data is loaded\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "# \n",
    "# # Plot distributions of numeric columns\n",
    "# numeric_cols = df.select_dtypes(include=[np.number]).columns[:4]\n",
    "# for ax, col in zip(axes.flatten(), numeric_cols):\n",
    "#     df[col].hist(ax=ax, bins=30)\n",
    "#     ax.set_title(f'Distribution of {col}')\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dd7128",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data - uncomment when data is loaded\n",
    "# target_column = 'your_target_column'  # Change this to your target column name\n",
    "# \n",
    "# features, targets = processor.preprocess(df, target_column=target_column)\n",
    "# print(f\"Features shape: {features.shape}\")\n",
    "# print(f\"Targets shape: {targets.shape if targets is not None else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc350d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders - uncomment when data is loaded\n",
    "# train_loader, val_loader, _ = get_data_loaders(\n",
    "#     data_path,\n",
    "#     target_column=target_column,\n",
    "#     batch_size=32,\n",
    "#     train_split=0.8\n",
    "# )\n",
    "# \n",
    "# print(f\"Training batches: {len(train_loader)}\")\n",
    "# print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35160b",
   "metadata": {},
   "source": [
    "## 4. Model Definition and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model - uncomment and adjust when data is ready\n",
    "# input_dim = features.shape[1]\n",
    "# \n",
    "# model = create_model(\n",
    "#     model_type='weight_assignment',\n",
    "#     input_dim=input_dim,\n",
    "#     output_dim=1\n",
    "# )\n",
    "# model = model.to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1460c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop - uncomment when ready to train\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# \n",
    "# epochs = 50\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "# \n",
    "# for epoch in range(epochs):\n",
    "#     # Training\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "#     for inputs, targets in train_loader:\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "#         \n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs.squeeze(), targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "#     \n",
    "#     train_losses.append(epoch_loss / len(train_loader))\n",
    "#     \n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, targets in val_loader:\n",
    "#             inputs, targets = inputs.to(device), targets.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             val_loss += criterion(outputs.squeeze(), targets).item()\n",
    "#     val_losses.append(val_loss / len(val_loader))\n",
    "#     \n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_losses[-1]:.4f} - Val Loss: {val_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50f6a41",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Feature Weight Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history - uncomment after training\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(train_losses, label='Training Loss')\n",
    "# plt.plot(val_losses, label='Validation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training History')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize learned feature weights - uncomment after training\n",
    "# feature_weights = model.get_feature_weights().cpu().numpy()\n",
    "# \n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(range(len(feature_weights)), feature_weights)\n",
    "# plt.xlabel('Feature Index')\n",
    "# plt.ylabel('Weight')\n",
    "# plt.title('Learned Feature Importance Weights')\n",
    "# \n",
    "# # Add feature names if available\n",
    "# if processor.feature_columns:\n",
    "#     plt.xticks(range(len(feature_weights)), processor.feature_columns, rotation=45, ha='right')\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a991887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model - uncomment after training\n",
    "# from utils import save_model\n",
    "# save_model(model, '../models', 'trained_model.pt')\n",
    "# print(\"Model saved!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
